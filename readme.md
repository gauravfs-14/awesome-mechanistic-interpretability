# Awesome Mamba (S4 - Structured State Space Models)

![Awesome](https://awesome.re/badge.svg)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
![GitHub Contributors](https://img.shields.io/github/contributors/gauravfs-14/awesome-mechanistic-interpretability.svg)
![GitHub Last Commit](https://img.shields.io/github/last-commit/gauravfs-14/awesome-mechanistic-interpretability.svg)
[![GitHub Stars](https://img.shields.io/github/stars/gauravfs-14/awesome-mechanistic-interpretability.svg?style=social)](https://github.com/gauravfs-14/awesome-mechanistic-interpretability)
![GitHub Forks](https://img.shields.io/github/forks/gauravfs-14/awesome-mechanistic-interpretability.svg)

A carefully curated collection of high-quality libraries, projects, tutorials, research papers, and other essential resources focused on Mechanistic Interpretability, a growing subfield in machine learning interpretability research that aims to reverse-engineer neural networks into understandable computational components. This repository serves as a comprehensive and well-organized knowledge base for researchers, engineers, and enthusiasts working to uncover the inner workings of modern AI systems, particularly large language models (LLMs).

To ensure that the community stays updated on the latest developments, our repository is automatically updated with recent mechanistic interpretability papers from arXiv. This ensures timely access to new techniques, discoveries, and frameworks that are shaping the future of model transparency and alignment.

Whether you are investigating the circuits behind in-context learning, decoding attention heads in transformers, or exploring interpretability tools like activation patching and causal tracing, this collection serves as a centralized hub for everything related to Mechanistic Interpretability â€” enriched by original peer-reviewed contributions and hands-on research from the broader interpretability community.

## Last Updated
June 11, 2025 at 04:52:35 PM UTC


## Theorem

## Papers (0)

## Library

## Tutorial

### Written Tutorials

### Video Tutorials

## Contributing

We welcome contributions to this repository! If you have a resource that you believe should be included, please submit a pull request or open an issue. Contributions can include:

- New libraries or tools related to mechanistic interpretability
- Tutorials or guides that help users understand and implement mechanistic interpretability techniques
- Research papers that advance the field of mechanistic interpretability
- Any other resources that you find valuable for the community

## How to Contribute

1. Fork the repository.
2. Create a new branch for your changes.
3. Make your changes and commit them with a clear message.
4. Push your changes to your forked repository.
5. Submit a pull request to the main repository.

Before contributing, take a look at the existing resources to avoid duplicates.

## License

This repository is licensed under the [Creative Commons Attribution 4.0 International License (CC BY 4.0)](LICENSE). You are free to share and adapt the material, provided you give appropriate credit, link to the license, and indicate if changes were made.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gauravfs-14/awesome-mechanistic-interpretability)](https://star-history.com/#gauravfs-14/awesome-mechanistic-interpretability&Date)
